{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "def data_random_extraction(path, n, n_data):\n",
    "    column_names = [\"article_text\", \"abstract_text\", \"section_names\", \"sections\"]\n",
    "    indices = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        indices.append(i)\n",
    "    \n",
    "    dataframe = pd.DataFrame(columns=column_names, index=indices)\n",
    "    \n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    index = set()\n",
    "    data_index = 0\n",
    "    c = 0\n",
    "    \n",
    "    index = set(random.sample(range(n_data), n))\n",
    "    \n",
    "    for line in Lines:\n",
    "        if c in index:\n",
    "            cur = json.loads(line)\n",
    "            dataframe.loc[data_index]['article_text'] = cur['article_text']\n",
    "            dataframe.loc[data_index]['abstract_text'] = cur['abstract_text']\n",
    "            dataframe.loc[data_index]['section_names'] = cur['section_names']\n",
    "            dataframe.loc[data_index]['sections'] = cur['sections']\n",
    "            data_index += 1\n",
    "            \n",
    "        c += 1\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(path, n, n_data):\n",
    "    column_names = [\"article_text\", \"abstract_text\", \"section_names\"]\n",
    "    indices = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        indices.append(i)\n",
    "    \n",
    "    dataframe = pd.DataFrame(columns=column_names, index=indices)\n",
    "    \n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    # data_index = 0\n",
    "    row = 0\n",
    "    \n",
    "    for line in Lines:\n",
    "        if row < n:\n",
    "            cur = json.loads(line)\n",
    "            \n",
    "            corpus = ''\n",
    "            for sentence in cur['abstract_text']:\n",
    "                corpus += sentence\n",
    "            dataframe.loc[row]['abstract_text'] = corpus.replace('<S> ', '').replace(' </S>', '')\n",
    "            \n",
    "            corpus = ''\n",
    "            for section in cur['sections']:\n",
    "                for sentence in section:\n",
    "                    corpus += sentence\n",
    "            dataframe.loc[row]['article_text'] = corpus\n",
    "            \n",
    "            dataframe.loc[row]['section_names'] = cur['section_names']\n",
    "            \n",
    "            row += 1\n",
    "        \n",
    "        else: break\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 203037\n",
    "n_test = 6440\n",
    "n_val = 6436\n",
    "\n",
    "new_train = data_extraction('C:\\\\Users\\\\ivanj\\\\Desktop\\\\Grad_School\\\\ESE527\\\\arxiv-dataset\\\\train.txt', n_train//13, n_train)\n",
    "new_test = data_extraction('C:\\\\Users\\\\ivanj\\\\Desktop\\\\Grad_School\\\\ESE527\\\\arxiv-dataset\\\\test.txt', n_test//13, n_test)\n",
    "new_val = data_extraction('C:\\\\Users\\\\ivanj\\\\Desktop\\\\Grad_School\\\\ESE527\\\\arxiv-dataset\\\\val.txt', n_val//13, n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215913"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train + n_test + n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>section_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>additive models @xcite provide an important fa...</td>\n",
       "      <td>additive models play an important role in semi...</td>\n",
       "      <td>[introduction, main results on learning rates,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the leptonic decays of a charged pseudoscalar ...</td>\n",
       "      <td>we have studied the leptonic decay @xmath0 , v...</td>\n",
       "      <td>[[sec:introduction]introduction, [sec:detector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the transport properties of nonlinear non - eq...</td>\n",
       "      <td>in 84 , 258 ( 2000 ) , mateos conjectured that...</td>\n",
       "      <td>[introduction, regularity and chaos in single-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studies of laser beams propagating through tur...</td>\n",
       "      <td>the effect of a random phase diffuser on fluct...</td>\n",
       "      <td>[introduction, the method of photon distributi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the so - called `` nucleon spin crisis '' rais...</td>\n",
       "      <td>with a special intention of clarifying the und...</td>\n",
       "      <td>[introduction, model lagrangian with pion mass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15613</th>\n",
       "      <td>the scattering of an unpolarized electron beam...</td>\n",
       "      <td>the spin polarized charge transport is systema...</td>\n",
       "      <td>[introduction, model, stationary current, spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15614</th>\n",
       "      <td>the variability of the light - curve of a lens...</td>\n",
       "      <td>the influence of microlensing in the profiles ...</td>\n",
       "      <td>[introduction, microlensing effects at high op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15615</th>\n",
       "      <td>one of the main contemporary challenges of the...</td>\n",
       "      <td>the dynamics of two competing species in a fin...</td>\n",
       "      <td>[introduction, intuitive arguments, glossary a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15616</th>\n",
       "      <td>one of the most impressive successes of the st...</td>\n",
       "      <td>we determine the hadronic light - by - light s...</td>\n",
       "      <td>[introduction[sec:intro], conclusions[sec:conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15617</th>\n",
       "      <td>flavour changing neutral current ( fcnc ) proc...</td>\n",
       "      <td>we investigate the rare decay @xmath0 which re...</td>\n",
       "      <td>[introduction, the decay amplitude for @xmath0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15618 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_text  \\\n",
       "0      additive models @xcite provide an important fa...   \n",
       "1      the leptonic decays of a charged pseudoscalar ...   \n",
       "2      the transport properties of nonlinear non - eq...   \n",
       "3      studies of laser beams propagating through tur...   \n",
       "4      the so - called `` nucleon spin crisis '' rais...   \n",
       "...                                                  ...   \n",
       "15613  the scattering of an unpolarized electron beam...   \n",
       "15614  the variability of the light - curve of a lens...   \n",
       "15615  one of the main contemporary challenges of the...   \n",
       "15616  one of the most impressive successes of the st...   \n",
       "15617  flavour changing neutral current ( fcnc ) proc...   \n",
       "\n",
       "                                           abstract_text  \\\n",
       "0      additive models play an important role in semi...   \n",
       "1      we have studied the leptonic decay @xmath0 , v...   \n",
       "2      in 84 , 258 ( 2000 ) , mateos conjectured that...   \n",
       "3      the effect of a random phase diffuser on fluct...   \n",
       "4      with a special intention of clarifying the und...   \n",
       "...                                                  ...   \n",
       "15613  the spin polarized charge transport is systema...   \n",
       "15614  the influence of microlensing in the profiles ...   \n",
       "15615  the dynamics of two competing species in a fin...   \n",
       "15616  we determine the hadronic light - by - light s...   \n",
       "15617  we investigate the rare decay @xmath0 which re...   \n",
       "\n",
       "                                           section_names  \n",
       "0      [introduction, main results on learning rates,...  \n",
       "1      [[sec:introduction]introduction, [sec:detector...  \n",
       "2      [introduction, regularity and chaos in single-...  \n",
       "3      [introduction, the method of photon distributi...  \n",
       "4      [introduction, model lagrangian with pion mass...  \n",
       "...                                                  ...  \n",
       "15613  [introduction, model, stationary current, spin...  \n",
       "15614  [introduction, microlensing effects at high op...  \n",
       "15615  [introduction, intuitive arguments, glossary a...  \n",
       "15616  [introduction[sec:intro], conclusions[sec:conc...  \n",
       "15617  [introduction, the decay amplitude for @xmath0...  \n",
       "\n",
       "[15618 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'C:\\\\Users\\\\ivanj\\\\Desktop\\\\Grad_School\\\\ESE527\\\\arxiv-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(dataset_path+'\\\\new_train.csv')\n",
    "new_test.to_csv(dataset_path+'\\\\new_test.csv')\n",
    "new_val.to_csv(dataset_path+'\\\\new_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code were adepted from \n",
    "# https://medium.com/@ferlatti.aldo/fine-tuning-a-chat-summarizer-c18625bc817d\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "    #get all the dialogues\n",
    "    inputs = [dialogue for dialogue in data_to_process['article_text']]\n",
    "    #tokenize the dialogues\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input, padding='max_length', truncation=True)\n",
    "    #tokenize the summaries\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        targets = tokenizer(data_to_process['abstract_text'], max_length=max_target, padding='max_length', truncation=True)\n",
    "\n",
    "    #set labels\n",
    "    model_inputs['labels'] = targets['input_ids']\n",
    "    #return the tokenized data\n",
    "    #input_ids, attention_mask and labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/yifeng/.cache/huggingface/datasets/csv/arxiv-dataset-935f63ede0f5d4ff/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11912351c18042618ae13f98f711bbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"/Users/yifeng/Desktop/Grad/ESE527/arxiv-dataset/\", data_files={\"train\": 'new_train.csv', 'test': 'new_test.csv', \"validate\": \"new_val.csv\"})\n",
    "tokenize_data = data.map(preprocess_data, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/gzjjnwn16kb_zpz40lt9bhx40000gn/T/ipykernel_80447/2736189134.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('rouge')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d93b75c7a434a2a9ee29d9572bf5344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input = 512\n",
    "max_target = 128\n",
    "batch_size = 3\n",
    "model_checkpoints = \"facebook/bart-large-xsum\"\n",
    "metric = load_metric('rouge')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
    "collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(pred):\n",
    "    predictions, labels = pred\n",
    "    #decode the predictions\n",
    "    decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    #decode labels\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    #compute results\n",
    "    res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n",
    "    #get %\n",
    "    res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n",
    "\n",
    "    pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    res['gen_len'] = np.mean(pred_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/yifeng/.cache/huggingface/hub/models--facebook--bart-large-xsum/snapshots/2179ab81d3f133e639f2957aec5380e9d56b2783/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large-xsum\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/yifeng/.cache/huggingface/hub/models--facebook--bart-large-xsum/snapshots/2179ab81d3f133e639f2957aec5380e9d56b2783/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-xsum.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /Users/yifeng/.cache/huggingface/hub/models--facebook--bart-large-xsum/snapshots/2179ab81d3f133e639f2957aec5380e9d56b2783/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract_text, article_text, section_names, Unnamed: 0. If abstract_text, article_text, section_names, Unnamed: 0 are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/Users/yifeng/opt/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 6\n",
      "  Number of trainable parameters = 406290432\n",
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 20:50, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.838084</td>\n",
       "      <td>20.341100</td>\n",
       "      <td>5.428500</td>\n",
       "      <td>13.835300</td>\n",
       "      <td>13.796700</td>\n",
       "      <td>36.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.712173</td>\n",
       "      <td>23.315500</td>\n",
       "      <td>6.940200</td>\n",
       "      <td>14.419200</td>\n",
       "      <td>14.399700</td>\n",
       "      <td>45.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.675076</td>\n",
       "      <td>28.463500</td>\n",
       "      <td>7.729100</td>\n",
       "      <td>17.125200</td>\n",
       "      <td>17.163400</td>\n",
       "      <td>60.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract_text, article_text, section_names, Unnamed: 0. If abstract_text, article_text, section_names, Unnamed: 0 are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract_text, article_text, section_names, Unnamed: 0. If abstract_text, article_text, section_names, Unnamed: 0 are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: abstract_text, article_text, section_names, Unnamed: 0. If abstract_text, article_text, section_names, Unnamed: 0 are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=4.837347666422526, metrics={'train_runtime': 1348.5288, 'train_samples_per_second': 0.022, 'train_steps_per_second': 0.004, 'total_flos': 30339464429568.0, 'train_loss': 4.837347666422526, 'epoch': 2.8})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    'paper-summary', #save directory\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size= 2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps=3,\n",
    "    fp16=False #available only with CUDA\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset=tokenize_data['train'],\n",
    "    eval_dataset=tokenize_data['validate'],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_rouge\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 2\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'</s><s>for about 20 years the problem of properties of short - term changes of solar activity has been considered.many investigators studied the short - time periodicities of the various indices of the solar activity.several periodicities were detected, but the periodicities about 155 days and from the interval of @x</s>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = new_test.loc[0]['article_text']\n",
    "model_inputs = tokenizer(test,  max_length=max_input, padding='max_length', truncation=True)\n",
    "raw_pred, _, _ = trainer.predict([model_inputs])\n",
    "tokenizer.decode(raw_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s><s>for about 20 years the problem of properties of short - term changes of solar activity has been considered.many investigators studied the short - time periodicities of the various indices of the solar activity.several periodicities were detected, but the periodicities about 155 days and from the interval of @x</s>'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(raw_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
